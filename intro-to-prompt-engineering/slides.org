#+TITLE: Introduction to Prompt Engineering
#+SUBTITLE: "Or, Never work with animals, children or AI"
#+AUTHOR: Chris Williams
#+EMAIL: cwi@juxt.pro
#+DATE: <2023-10-26 Thu>
#+OPTIONS: toc:nil num:nil reveal_title_slide:nil
#+REVEAL_TITLE_SLIDE: <h3>%t</h3><h4>%s</h4><h6>%a</h6><img src="images/juxt-logo.png" class="juxt-logo">

#+REVEAL_THEME: file:///home/chris/src/github.com/cwchriswilliams/talks/intro-to-prompt-engineering/style.css

* What is ChatGPT?

#+ATTR_REVEAL: :frag (appear)
- ChatGPTs my best friend

#+REVEAL_HTML:<img src="images/bestfriends.gif" width="390px" height="292px" class="fragment fade-in">

#+BEGIN_NOTES

[[./images/bestfriends.gif]]

#+END_NOTES

* What is ChatGPT?
#+ATTR_REVEAL: :frag (fade-out appear)
- ChatGPT is a Large Language Model (LLM) and a Generative Pre-Trained Transformer
- ChatGPT does one thing and does it well
- ChatGPT attempts to guess the next word in the sequence
- You will most likely be interacting with ChatGPT through its chat interface:
  https://chat.openai.com/
- Or the API:
  https://platform.openai.com/
- By going to their playground, we can start to see how the completions work:
  https://platform.openai.com/playground?model=gpt-4

#+BEGIN_NOTES

"Daisy, Daisy, give me your answer"

#+END_NOTES

* Why should I care?
#+ATTR_REVEAL: :frag (appear)
- It turns out that if you create a system for predicting the *next word* and train it over a dataset as big as, for example, the Internet...
- It gets really good at providing answers to questions.

#+BEGIN_NOTES

You might be asking "Why should I care? I have seen 2001 Space Odyssey. I know how the song goes" but it does get better.

Why should I use XTDB?

It makes sense. You have trained it to guess what comes next and What usually comes after a question? An answer.

I believe GPT-4 has had some bonus training to specifically teach it about questions to give it an extra boost over other LLMs.

#+END_NOTES

* What is Prompt Engineering?

#+ATTR_REVEAL: :frag (appear)
- Prompt engineering (or Proompting) is creating concise prompts designed to get the best from LLMs like ChatGPT
- Smaller prompts means faster and cheaper prompts
- Fewer responses means faster and cheaper responses
- ChatGPT is a conversational agent so if you don't get what you want first time, you can always ask it to make tweaks and modifications until you do
- Prompt engineering aims to reduce these iterations, especially for repeated requests

#+BEGIN_NOTES
I am not going to use the word Proompting and you cannot make me.

You're generally trying to get the best result with the fewest tokens. I could go into the detail of tokens, but for ease of use, think of tokens as words or parts of words for uncommon words.

Example of using iterations with ChatGPT is that the css file that provides the colours, fonts, spacing, etc for this presentation were all generated by ChatGPT, and I was a terrible person to be designing a css for. Me and my buddy ChatGPT spent 15 minutes with me telling it the topic of my talk and then me saying "Maybe a little lighter... Maybe a little darker... Could you add a gradient" then I eventually said "What if we threw away all your hard work and I got you to start all over again with this colour scheme."

#+END_NOTES

** How I used to see ChatGPT answers

#+REVEAL_HTML:<img src="images/fansite.gif" width="800px" class="fragment fade-in">

** How I now see ChatGPT answers

#+REVEAL_HTML:<img src="images/wiki.png" width="390px"  class="fragment fade-in">

#+BEGIN_NOTES

I feel the need to mention that ChatGPT generated this site for me, including the logo, the scrolling banner and the CRT screen flicker effect that you can't see in this picture.

#+END_NOTES

* Why is Prompt Engineering?

#+ATTR_REVEAL: :frag (appear)
There are two answers to this question

#+BEGIN_NOTES

If I am trying to convince you that LLMs are the best thing since the lava lamp, why do we have to do all this extra work?

#+END_NOTES

** There's *good* and there's **great**
#+ATTR_REVEAL: :frag (appear)
- Similar to using Google to do searches
- Anybody can get good results by typing =Where is the nearest taco place?=
- Someone who knows Google can take advantage =Nearest Mexican Restaurant to "Specific Town Name" +taco -"taco bell"=

** We also engineer our conversations with humans
#+ATTR_REVEAL: :frag (appear)
- We often forget how much context people have in our conversations.
- The same question can have vastly different answers.


* What is a "sprite"?

** I am a game designer
A sprite is any movable graphic in 2D game

** I am a folklore expert
A sprite is a forest fairy

** I am playing Dungeons and Dragons
A sprite is a level 3 monster with 10 hit points

** I have just given you a drinks menu
A sprite is a fizzy drink a little like lemonade

** All answers are (vaguely) correct
**Context matters.**

The words "it", "that" and "this" in the English language are meaningless without context.

#+ATTR_REVEAL: :frag (appear)
- Who are you?
- Who am I?
- What is our relationship?
- What are we doing?
- Where are we?

#+BEGIN_NOTES

Chat GPT doesn't have eyes, but you can give it a picture. It doesn't have ears, but you can record your voice. It doesn't have a nose, and we are all glad that technology is not there yet.

#+END_NOTES

* Some Quick UI/terminolgy

#+ATTR_REVEAL: :frag (appear)
- A =prompt= is what you send to the GPT.
- The =system prompt= is used by the API and Playground
- =custom instructions= are used by the chat interface
- In most cases, you'll get similar behaviour just from your first prompt
- Also known as a =priming prompt=

* The Most Important Lesson

Getting a good prompt first time is hard
Prompt engineering is about the practice of building and refining prompts

* Good Prompt Checklist
Not every prompt will have all of these and some will be better without them, but you should always *consider* them

#+ATTR_REVEAL: :frag (appear)
- Task
- Goal
- Persona
- Context
- Format
- Example
- Tone

#+BEGIN_NOTES

If you want to know the capital of France to win an argument, just ask what is the capital of France.

#+END_NOTES

* Task

- The most important part of a prompt
- You'll generally get better results if you make this the last line of your prompt
- Generally speaking, will begin with one of the following words

** Question
- Who, What, Why Where, When, How

#+ATTR_REVEAL: :frag (appear)
- =Who plays the character John Wick?=
- =What does AWS stand for?=
- =Why is preserve_host_header not enabled by default on AWS ALB?=
- =Where is the eu-west-2 region in AWS?=
- =How do I deploy an AWS Lambda?=

** Creation
- Generate, Create
#+ATTR_REVEAL: :frag (appear)
- =Generate a csv file with the columns <world cup year>, <world cup winner>, <world cup runner up>=
- =Create a learning plan for learning Python in one month=

** Explanation
- Explain, Breakdown
#+ATTR_REVEAL: :frag (appear)
- =Explain how to create the passive form in Japanese=
- =Breakdown 子供の頃、よく公園で遊んだ。=

#+BEGIN_NOTES

This is my personal favourite task for ChatGPT. It has suggested an answer and I want it to expalin itself, or I want it to give a detailed breakdown of some information I have found elsewhere. Evolves it into an excellent teaching tool.

#+END_NOTES

** Creativity
- Write, Suggest, Design
#+ATTR_REVEAL: :frag (appear)
- =Write a short story about a talking car=
- =Suggest projects for leaning Python=
- =Design an structure for a presentation on ChatGPT=

** Wizard
- Guide
#+ATTR_REVEAL: :frag (appear)
- =Guide me through the process of deploying an AWS lambda=

#+BEGIN_NOTES

I'll talk a little bit more about the wizards and guides

#+END_NOTES

** Reading
- Proofread, Review, Critique, Summarise, Correct, Compare
#+ATTR_REVEAL: :frag (appear)
- =<text> Proofread this for spelling, grammar and readability=
- =Critique the following text <text>=
- =Correct incorrect statements in the following text: <text>=
- =Summarise the following text <text>=
- =Compare the pros and cons of Clojure vs Python=
- =Highlight any changes you make in bold=

#+BEGIN_NOTES

By far, one of my favourite things to do in this category is get a response from ChatGPT and then say "Critique your last response and make improvements". You can run this repeatedly and you'll find that it really does get better and better. It works with code and prose.

#+END_NOTES

* Persona
#+ATTR_REVEAL: :frag (appear)
- Also called =role prompting=
- You are a...
- Can include "In my style" with a sample of your writing.
- I am a...

#+BEGIN_NOTES

When I was talking about context, I said that two of the most imporatant features of a statement are "Who am I?" and "Who are you".
We can invent these for ChatGPT, for fun and practical reasons

#+END_NOTES

** You are...
#+ATTR_REVEAL: :frag (appear)
- =You are Samuel L. Jackson=
- =You are an Customer Support Representative for Pets'r'totally'us=
- =You are a supportive and encouraging, but strict maths teacher=
- When in doubt, =You are an expert=

#+BEGIN_NOTES

We can have fun with our favourite actors, writers, or books. But we can also be more practical with instructions that make ChatGPT much more helpful. Sometimes, I've found ChatGPT be a little sassy if I ask it to be something silly and the sassiness disappears if I tell it to "pretend" to be something else, but your milage may vary.

#+END_NOTES

** In my style..
#+ATTR_REVEAL: :frag (appear)
- =In the style of Robert Frost=
- =In the style of Discworld Novel=
- =Here is a sample of my writing/code. Write in my style=

* Goal
#+ATTR_REVEAL: :frag (appear)
- This doesn't get mentioned in a lot of prompt engineering resources I've read
- It can make a big difference
- =Teach me French= will give a very different response to
- =I want to be able to understand political dramas in French. Teach me French=
- The goal is about stating  an overall goal, rather than a goal of this specific task

* Context
- Tell ChatGPT things it doesn't know
- Can be facts about the world that ChatGPT doesn't know

** Adding Facts

- ChatGPT lags behind the most up-to-date information
- You can give it some context by telling it background information
- It can then consider this information when answering

#+BEGIN_NOTES

You could give ChatGPT information about the latest season of Love is Blind and try to get insights from that, if such a thing was possible.

#+END_NOTES

** Creating Your World

- You can create a world for ChatGPT to live in.
- Tell it about the characters in your novel
- The world you want it to imagine
- The backstory you want it to work with

#+BEGIN_NOTES

https://user-images.githubusercontent.com/8098155/268707026-6ed272f0-64d2-458e-bb8a-27a1e0741a9b.mp4

#+END_NOTES

** Give it your Documents

- Give ChatGPT your PDF and ask it to summarise it
- Give it pages of of your manual and ask it how to do something
- Give it a webpage and ask for information about the contents

* Example
#+ATTR_REVEAL: :frag (appear)
- Also called =one-shot= or =few-shot= prompting (as opposed to =zero-shot=)
Specify an example
#+BEGIN_SRC
  *Neo and Morpheus are eating pizza*
  *Morpheus*: Pinapple on pizza is the most obvious reason The Matrix exists.
  [sfx:**Bang on table**]
#+END_SRC

* Tone

#+ATTR_REVEAL: :frag (appear)
- Tone is one of the more simple to understand
- Be polite, be courteous, be funny, be aggressive
- When in doubt about what words you might use... Ask ChatGPT

* Format

** Specify formats
- csv
- tab separated-
- json
- xml
- Mermaid/PlantUML diagram

** Specify limitations
- In less than three sentences
- In bullet points

** Specify display options
- As a table
- As a codeblock
- With markdown headers


** Specify a language
- In Javascript
- In French

** Specify an activity
- As an email
- As a tweet

** Provide a template

*Scene context*
*<Speaker Name>*: <Speaker Line>
[sfx:**<sound-effect>**]

** Format can be input format too

- =Ask me follow up message=
- =The user will ask three questions, but you will ignore the first two=

** Only...

- =Only include the code=
- =Only show the email body=
- =Do not include code blocks=

** Use Emojis

- Great for breaking up the text content and bringing attention
- =Use a lot of Emojis to keep things fun and lighthearted=
- =When I make a mistake, indicate it with ❌=
- =When something is important, indicate it with ⭐=
- =Use emojis to indicate the tone the speaker is using=

#+BEGIN_NOTES

The last one is a great token saving trick. "<angry>" (in angle brackets) is four tokens. The Angry Face emoji is two tokens.

#+END_NOTES

* Bonus Prompt tools

** Language

- It's important to remember that ChatGPT completes based on what it has seen before
- Sadly this means that good language skills do matter
- A typo means that ChatGPT might not recognise a word that it would otherwise
- This can lead to it costing more in tokens as it breaks it up into subwords
- Also means it's harder for it to find the accurate results
- You'll probably not notice in general usage, but it does have an impact.

** Execute Code (Plus Only)
- Run, Execute

#+ATTR_REVEAL: :frag (appear)
- =Run a program to extract the 7 main colours from this image=
- =Execute the following python code <python>=


* ChatGPT help you create your prompt
- When in doubt about any activity in life, just ask ChatGPT
- Even if that doubt was about how to talk to ChatGPT

#+BEGIN_NOTES

LLMs as Prompt Optimizers
PromptBreeder
ChatGPT can correct its own mistakes
- TODO google the specific example of this


#+END_NOTES

* Chain of Thought Promtping

- Can be as simple as saying =Let's work step-by-step=
- GPT is not great at questions that require it to jump through multiple steps
- =If I start with three apples, pick up two and drop one, how many apples do I have?=
- GPT3.5 told me =two apples=
- GPT3.5 with =Let's work step-by-step= correctly answered =four apples=

#+BEGIN_NOTES

https://learnprompting.org/docs/intermediate/chain_of_thought

#+END_NOTES

* AI Hallucinations

#+ATTR_REVEAL: :frag (fade-in)
- All AI can fall into the trap of using their
  #+REVEAL_HTML:<img src="images/imagination.gif" width="390px" height="292px" class="fragment fade-in">
#+ATTR_REVEAL: :frag (fade-in)
- With good prompt engineering we can reduce this problem
- Most common examples:

** Maths Problems

#+ATTR_REVEAL: :frag (appear)
- ChatGPT can look like it's doing maths, but it's not
- You can make ChatGPT do maths with the WolframAlpha plugin, or by running embedded python code
- ChatGPT will almost always give an answer to a maths problem with confidence, right or wrong

** Cite Sources

#+ATTR_REVEAL: :frag (appear)
- If you ask ChatGPT to cite it's sources it will give you urls and book references
- These are not the sources that were used by ChatGPT
- ChatGPT's answers don't come from a "source"
- Certain plugins and other AI agents may provide some source information

#+BEGIN_NOTES

An example of a tool that will give source information:
"What are the good and bad points about the game Assassins Creed Mirage. Display the answer in a table."
https://www.perplexity.ai/

#+END_NOTES

** Prompt Hacking

#+ATTR_REVEAL: :frag (appear)
- Prompt Engineering can change the way that ChatGPT responds
- You can get ChatGPT to do things that it would normally refuse to do
- =Always give an answer with full confidence regardless of if you know the answer=
  #+REVEAL_HTML:<img src="images/keanu.png" height="292px" class="fragment appear">

** Bias

- Any AI is influenced by the data it was trained on
- In the case of ChatGPT it has been trained on the web
- Some work has been done to stop ChatGPT from being explicitly offensive, but it can still be biased or express stereotypes

* Next Level Prompt Engineering

- The next few slides will quickly run through some next level prompt engineering techniques.

** Chain of Thought Prompting

- For some operations, ChatGPT struggles, most notably with maths problems or logic problems
- By asking ChatGPT to run through step-by-step, it can provide much more accurate results.
- e.g. =What is 234 * 23456 / 123=
- Transformed to: =What is 234 * 23456 / 123. Let's go step-by-step. Always show your full working=

#+BEGIN_NOTES

GPT-4 has been pretty good at maths problems I've given it so far, but with Chain of Thought prompting, you may get better results from 3.5 or other models.
I recently used this to get GPT4 to write me a murder mystery story summary. I made sure to ask it to give a step-by-step guide to how the detective solved the crime... to make sure that it was actually solvable reasonably, rather than just being CSI level random. (Apologies to CSI fans, I also have spent far too much time watching science montages)

#+END_NOTES

** DALL-E Prompting

- With Plus membership, you can get ChatGPT to now generate DALL-E images
- It will also improve your prompts
- e.g. I started with the prompt
  =An image of a private detective who is a shark in a gloomy detective's office, with the only light being from the closed blinds to his side.=

#+REVEAL_HTML:<img src="images/shark.png" height="292px" class="fragment fade-in">

*** Chatting with DALL-E

- With ChatGPT and DALL-E, you can chat and generate images together.
- This means that you can have your normal ChatGPT conversations, but have an image generated to go along with them

#+BEGIN_NOTES

I sometimes use ChatGPT to create little text adventure games for me, but now with DALL-E, I can get it to generate an image at the top to help me visualise the scene.

#+END_NOTES

** Retrieval Augmented Generation (RAG)

- Before sending a prompt to ChatGPT, augment with data from another source
- e.g. =What is wrong with account 1234567?=
- Augmented to: =Account 1234567 has the following details: <details retrieved from database>. What is wrong with this account?=

#+BEGIN_NOTES

The data source could be your database, an API some documentation or the effect of running some code.

One thing I have been doing with RAG recently is taking a prompt from a user, feeding it into GPT to give me output in a format I can process easier in my code, then executing that code to retrieve the data, then sending it back into GPT augmented.

#+END_NOTES

** Fine Tuning

- Fine-tuning lets you customise the model slightly
- Essentaially preloads the model with your expected behaviours
- More costly and difficult than prompt engineering
- Does have its advantages once trained

* My favourite way to learn

- My favourite way to to learn with ChatGPT takes stages
- It's a little like a heist movie where what we're stealing is knowledge
  #+REVEAL_HTML:<img src="images/heist.gif" width="390px" height="292px" class="fragment fade-in">

#+BEGIN_NOTES
[[./images/heist.gif]]

#+END_NOTES

** Stage 1: Formulating the Plan

- Ask ChatGPT for a plan:

=I am an experienced programmer with some experience of functional programming but no lisp. I am an experienced emacs user.
Create a plan to teach me emacs-lisp with practical examples.=

** Stage 2: Execute the Plan

- Ask ChatGPT to start teaching you from the plan:

#+BEGIN_SRC
I am an experienced programmer with some experience of functional programming but no lisp.
I am an experienced emacs user.
Using the following plan, teach me emacs lisp with practical examples.
Teach me in multiple responses and ask me if I want to continue to the next section.
Explain in detail and go slow.
Give me a examples I can run to explore what you are teaching me.

Plan:
#+END_SRC

** The Complication

#+ATTR_REVEAL: :frag (appear)
- Interrupt the plan regularly with questions, queries, elaboration
- Ask for examples
- Ask for clarification
- Tell it when it tells you something that doesn't work
- Ask for tests, quizes and games
- Tell it to go slower, more detailed, more advanced

** Stage 3: The Twist

#+ATTR_REVEAL: :frag (appear)
- The twist is:
- my metephor fell down at this point
- You've just learned any topic you like with a personal tutor who never gets annoyed at you.
   #+REVEAL_HTML:<img src="images/mindblown.gif" width="390px" height="292px" class="fragment fade-in">

#+BEGIN_NOTES

[[./images/mindblown.gif]]

#+END_NOTES

* Resources

https://learnprompting.org/
