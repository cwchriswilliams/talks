#+TITLE: Introduction to Prompt Engineering
#+SUBTITLE: "Or, Never work with animals, children or AI"
#+AUTHOR: Chris Williams
#+EMAIL: cwi@juxt.pro
#+DATE: <2023-10-26 Thu>
#+OPTIONS: toc:nil num:nil reveal_title_slide:nil
#+REVEAL_TITLE_SLIDE: <h3>%t</h3><h4>%s</h4><h6>%a</h6><img src="images/juxt-logo.png" class="juxt-logo">

#+REVEAL_THEME: file:///home/chris/src/github.com/cwchriswilliams/talks/intro-to-prompt-engineering/style.css

* What is ChatGPT?

#+ATTR_REVEAL: :frag (appear)
- ChatGPTs my best friend

#+REVEAL_HTML:<img src="images/bestfriends.gif" width="390px" height="292px" class="fragment fade-in">

#+BEGIN_NOTES

[[./images/bestfriends.gif]]


#+END_NOTES

* What is ChatGPT?
#+ATTR_REVEAL: :frag (fade-out appear)
- ChatGPT is a Large Language Model (LLM) and a Generative Pre-Trained Transformer
- ChatGPT does one thing and does it well
- ChatGPT attempts to guess the next word in the sequence
- You will most likely be interacting with ChatGPT through its chat interface:
  https://chat.openai.com/
- Or the API:
  https://platform.openai.com/
- By going to their playground, we can start to see how the completions work:
  https://platform.openai.com/playground?model=gpt-4

#+BEGIN_NOTES

"Daisy, Daisy, give me your answer"

#+END_NOTES

* Why should I care?
#+ATTR_REVEAL: :frag (appear)
- It turns out that if you create a system for predicting the *next word* and train it over a dataset as big as, for example, the Internet...
- It gets really good at providing answers to questions.

#+BEGIN_NOTES

You might be asking "Why should I care? I have seen 2001 Space Odyssey. I know how the song goes" but it does get better.

Why should I use XTDB?

It makes sense. You have trained it to guess what comes next and What usually comes after a question? An answer.

I believe GPT-4 has had some bonus training to specifically teach it about questions to give it an extra boost over other LLMs.

#+END_NOTES

* What is Prompt Engineering?

#+ATTR_REVEAL: :frag (appear)
- Prompt engineering (or Proompting) is creating concise prompts designed to get the best from LLMs like ChatGPT
- Smaller prompts means faster and cheaper prompts
- Fewer responses means faster and cheaper responses
- ChatGPT is a conversational agent so if you don't get what you want first time, you can always ask it to make tweaks and modifications until you do
- Prompt engineering aims to reduce these iterations, especially for repeated requests

#+BEGIN_NOTES
'
I am not going to use the word Proompting and you cannot make me.

Example of using iterations with ChatGPT is that the css file that provides the colours, fonts, spacing, etc for this presentation were all generated by ChatGPT, and I was a terrible person to be designing a css for. Me and my buddy ChatGPT spent 15 minutes with me telling it the topic of my talk and then me saying "Maybe a little lighter... Maybe a little darker... Could you add a gradient" then I eventually said "What if we threw away all your hard work and I got you to start all over again with this colour scheme."

#+END_NOTES


* Why is Prompt Engineering?

#+ATTR_REVEAL: :frag (appear)
There are two answers to this question

#+BEGIN_NOTES

If I am trying to convince you that LLMs are the best thing since the lava lamp, why do we have to do all this extra work?

#+END_NOTES

** There's *good* and there's **great**
#+ATTR_REVEAL: :frag (appear)
- Similar to using Google to do searches
- Anybody can get good results by typing =Where is the nearest taco place?=
- Someone who knows Google can take advantage =Nearest Mexican Restaurant to "Specific Town Name" +taco -"taco bell"=

** We also engineer our conversations with humans
#+ATTR_REVEAL: :frag (appear)
- We often forget how much context people have in our conversations.
- The same question can have vastly different answers.


* What is a "sprite"?

** I am a game designer
A sprite is any movable graphic in 2D game

** I am a folklore expert
A sprite is a forest fairy

** I am playing Dungeons and Dragons
A sprite is a level 3 monster with 10 hit points

** I have just given you a drinks menu
A sprite is a fizzy drink a little like lemonade

** All answers are (vaguely) correct
**Context matters.**

The words "it", "that" and "this" in the English language are meaningless without context.

#+ATTR_REVEAL: :frag (appear)
- Who are you?
- Who am I?
- What is our relationship?
- What are we doing?
- Where are we?

#+BEGIN_NOTES

Chat GPT doesn't have eyes, but you can give it a picture. It doesn't have ears, but you can record your voice. It doesn't have a nose, and we are all glad that technology is not there yet.

#+END_NOTES

* Some Quick UI/terminolgy

#+ATTR_REVEAL: :frag (appear)
- A =prompt= is what you send to the GPT.
- The =system prompt= is used by the API and Playground
- =custom instructions= are used by the chat interface
- In most cases, you'll get similar behaviour just from your first prompt

* The Most Important Lesson

Getting a good prompt first time is hard
Prompt engineering is about the practice of building and refining prompts

* Good Prompt Checklist
Not every prompt will have all of these and some will be better without them, but you should always *consider* them

#+ATTR_REVEAL: :frag (appear)
- Task
- Goal
- Persona
- Context
- Format
- Example
- Tone

#+BEGIN_NOTES

If you want to know the capital of France to win an argument, just ask what is the capital of France.

#+END_NOTES

* Task

- The most important part of a prompt
- Generally speaking, will begin with one of the following words

** Question
- Who, What, Why Where, When, How

#+ATTR_REVEAL: :frag (appear)
- =Who plays the character John Wick?=
- =What does AWS stand for?=
- =Why is preserve_host_header not enabled by default on AWS ALB?=
- =Where is the eu-west-2 region in AWS?=
- =How do I deploy an AWS Lambda?=

** Creation
- Generate, Create
#+ATTR_REVEAL: :frag (appear)
- =Generate a csv file with the columns <world cup year>, <world cup winner>, <world cup runner up>=
- =Create a learning plan for learning Python in one month=

** Explanation
- Explain, Breakdown
#+ATTR_REVEAL: :frag (appear)
- =Explain how to create the passive form in Japanese=
- =Breakdown 子供の頃、よく公園で遊んだ。=

#+BEGIN_NOTES

This is my personal favourite task for ChatGPT. It has suggested an answer and I want it to expalin itself, or I want it to give a detailed breakdown of some information I have found elsewhere. Evolves it into an excellent teaching tool.

#+END_NOTES

** Creativity
- Write, Suggest, Design
#+ATTR_REVEAL: :frag (appear)
- =Write a short story about a talking car=
- =Suggest projects for leaning Python=
- =Design an structure for a presentation on ChatGPT=

** Wizard
- Guide
#+ATTR_REVEAL: :frag (appear)
- =Guide me through the process of deploying an AWS lambda=

#+BEGIN_NOTES

I'll talk a little bit more about the wizards and guides

#+END_NOTES

** Reading
- Proofread, Review, Critique, Summarise, Correct, Compare
#+ATTR_REVEAL: :frag (appear)
- =<text> Proofread this for spelling, grammar and readability=
- =Critique the following text <text>=
- =Correct incorrect statements in the following text: <text>=
- =Summarise the following text <text>=
- =Compare the pros and cons of Clojure vs Python=

#+BEGIN_NOTES

By far, one of my favourite things to do in this category is get a response from ChatGPT and then say "Critique your last response and make improvements". You can run this repeatedly and you'll find that it really does get better and better. It works with code and prose.

#+END_NOTES

* Persona
- You are a...
- Can include "In my style" with a sample of your writing.
- I am a...

#+BEGIN_NOTES

When I was talking about context, I said that two of the most imporatant features of a statement are "Who am I?" and "Who are you".
We can invent these for ChatGPT, for fun and practical reasons

#+END_NOTES

** You are...
- =You are Samuel L. Jackson=
- =You are an Customer Support Representative for Pets'r'totally'us=
- =You are a supportive and encouraging, but strict maths teacher=

#+BEGIN_NOTES

We can have fun with our favourite actors, writers, or books. But we can also be more practical with instructions that make ChatGPT much more helpful. Sometimes, I've found ChatGPT be a little sassy if I ask it to be something silly and the sassiness disappears if I tell it to "pretend" to be something else, but your milage may vary.

#+END_NOTES

** In my style..
- =In the style of Robert Frost=
- =In the style of Discworld Novel=
- =Here is a sample of my writing/code. Write in my style=

* Goal
- I want to...

* Context
- Limitations

* Example

Specify an example
#+BEGIN_SRC
  *Neo and Morpheus are eating pizza*
  *Morpheus*: Pinapple on pizza is the most obvious reason The Matrix exists.
  [sfx:**Bang on table**]
#+END_SRC

* Tone

Be polite, be courteous, be funny, be aggressive.

* Format

** Specify formats
- csv
- tab separated-
- json
- xml
- Mermaid/PlantUML diagram

** Specify limitations
- In less than three sentences
- In bullet points

** Specify display options
- As a table
- As a codeblock
- With markdown headers


** Specify a language
- In Javascript
- In French

** Specify an activity
- As an email
- As a tweet

** Provide a template

*Scene context*
*<Speaker Name>*: <Speaker Line>
[sfx:**<sound-effect>**]

** Format can be input format too

- Multiple questions

** Only...

- =Only include the code=
- =Only show the email body=


* Bonus Prompt tools

** Language

GPT completes.
Good language skills matter.
Tokenisation
Spelling and grammar


** Metadata

- Provide a condifence level
- Provide a url source for your resposne
- Make bold the changes you made/List the changes you made (For critiques)


** Execute Code (Plus Only)
- Run, Execute

#+ATTR_REVEAL: :frag (appear)
- =Run a program to extract the 7 main colours from this image=
- =Execute the following python code <python>=


* ChatGPT help you create your prompt
- When in doubt about any activity in life, just ask ChatGPT
- Even if that doubt was about how to talk to ChatGPT

#+BEGIN_NOTES

LLMs as Prompt Optimizers
PromptBreeder
ChatGPT can correct its own mistakes
- TODO google the specific example of this


#+END_NOTES

* Chain of Thought Promtping

#+BEGIN_NOTES

https://learnprompting.org/docs/intermediate/chain_of_thought
#+END_NOTES

* Didn't make the cut for this session
- Upload File (Plus Only)
- Search with Bing (Plus Only)
- GPT4-Vision
  - Visual Referral Prompting
- Plugins (Plus Only)


* AI Hallucinations

* Next Level Prompt Engineering

- The next few slides will quickly run through some next level prompt engineering techniques.

** Chain of Thought Prompting

- For some operations, ChatGPT struggles, most notably with maths problems or logic problems
- By asking ChatGPT to run through step-by-step, it can provide much more accurate results.
- e.g. =What is 234 * 23456 / 123=
- Transformed to: =What is 234 * 23456 / 123. Let's go step-by-step. Always show your full working=

#+BEGIN_NOTES

GPT-4 has been pretty good at maths problems I've given it so far, but with Chain of Thought prompting, you may get better results from 3.5 or other models.
I recently used this to get GPT4 to write me a murder mystery story summary. I made sure to ask it to give a step-by-step guide to how the detective solved the crime... to make sure that it was actually solvable reasonably, rather than just being CSI level random. (Apologies to CSI fans, I also have spent far too much time watching science montages)

#+END_NOTES

** DALL-E Prompting

- With Plus membership, you can get ChatGPT to now generate DALL-E images
- It will also improve your prompts
- e.g. I started with the prompt

** Retrieval Augmented Generation (RAG)

- Before sending a prompt to ChatGPT, augment with data from another source
- e.g. =What is wrong with account 1234567?=
- Augmented to: =Account 1234567 has the following details: <details retrieved from database>. What is wrong with this account?=

#+BEGIN_NOTES

The data source could be your database, an API some documentation or the effect of running some code.

One thing I have been doing with RAG recently is taking a prompt from a user, feeding it into GPT to give me output in a format I can process easier in my code, then executing that code to retrieve the data, then sending it back into GPT augmented.

#+END_NOTES

** Fine Tuning

- Fine-tuning lets you customise the model slightly
- Essentaially preloads the model with your expected behaviours
- More costly and difficult than prompt engineering
- Does have its advantages once trained

* My favourite way to learn

- My favourite way to to learn with ChatGPT takes stages
- It's a little like a heist movie where what we're stealing is knowlegde
  #+REVEAL_HTML:<img src="images/heist.gif" width="390px" height="292px" class="fragment fade-in">

** Stage 1: Formulating the Plan

- Ask ChatGPT for a plan:

=I am an experienced programmer with some experience of functional programming but no lisp. I am an experienced emacs user.
Create a plan to teach me emacs-lisp with practical examples.=

** Stage 2: Execute the Plan

- Ask ChatGPT to start teaching you from the plan:

=I am an experienced programmer with some experience of functional programming but no lisp. I am an experienced emacs user.
Using the following plan, teach me emacs lisp with practical examples. Teach me in multiple responses and ask me if I want to continue to the next section. Explain in detail and go slow. Give me a examples I can run to explore what you are teaching me.

Plan:=

** The Complication

- Interrupt the plan regularly with questions, queries, elaboration
- Ask for examples
- Ask for clarification
- Tell it when it tells you something that doesn't work

** Stage 3: The Twist

- The twist is, there is no twist.
- You've just learned any topic you like with a personal tutor who never gets annoyed at you.
   #+REVEAL_HTML:<img src="images/mindblown.gif" width="390px" height="292px" class="fragment fade-in">


* Examples of my chats


* TODO Add slide about pros and cons of a product
* TODO Add slide about neutral vs bias vs scientific vs only from sources

* Resources

https://learnprompting.org/


#+BEGIN_NOTES
'
#+END_NOTES
